[{"title":"Algorithm-based Fault Tolerant(基于算法的容错)","date":"2023-02-08T09:44:29.000Z","path":"2023/02/08/ABFT/","text":"对ABFT容错的浅薄理解原理是针对某一种算法中的高频算子进行可靠性设计，以在较低的成本下保障算法大部分的可靠性。目前看到的两篇论文都是通过冗余计算，计算校验和对比结果来实现容错机制。这种方法相比于架构层和电路层的方法来说代价要更低，更加灵活。 相关论文的主要方法是： 设计校对矩阵 设计checksum校对方法 分析一下校对算法开销如何、能够实现什么级别的容错(可检测or可修正) 设计相关的容错框架或者系统 通过实验验证可靠性保证以及额外开销。 以后也可以多思考一下相关的算子有没有这样的机会做冗余计算。 矩阵操作ABFT设计原文：Algorithm-Based Fault Tolerance for Matrix Operations(1984, TC) 校对矩阵设计 简单来说就是有个矩阵M，然后里面每个元素的最大值(位宽决定)为8。这个矩阵的行校验矩阵$M_r$就是增加新的一列，这一列是前面几列的和，这个矩阵可以用来定位错误所在的行；同样这个矩阵的列校验矩阵$M_c$也同理定义，用来定位错误所在的列。$M_f$是矩阵的全校验矩阵，可以实现错误的定位和修复。 检错方法 适用于矩阵乘、加、LU分解、标量乘、转置操作 可以实现单比特错误检测(右下角的数值C和整个结果矩阵的和对比)、定位、纠错(通过行和列定位后再算一下) 可以实现多比特错误检测。 卷积操作ABFT设计FT-CNN: Algorithm-Based Fault Tolerance for Convolutional Neural Networks 校对矩阵 在这个卷积操作里面假设输入矩阵D和W都是思维矩阵，校对矩阵中$C_{d1}$和$C_{d2}$分别是$D_i$的和以及加权和。如果在全校验的情况下，checkSum会有很多个；不同的checkSum的计算难度不同，其检错难度也不同，因此适用于不同的场景，或者可以分层次进行检测，以使本方法的开销更小一些。这就是本文的核心思想，其具体思路可以再重新找一下论文。 不同校验和组合产生的检错维度 检测原理：以Checksum of Checksum为例 检错能力和checksum的复杂度分析 分层的纠错框架 实验结果：开销","link":"","tags":[{"name":"容错","slug":"容错","permalink":"https://recoderchris.github.io/tags/%E5%AE%B9%E9%94%99/"},{"name":"SDC","slug":"SDC","permalink":"https://recoderchris.github.io/tags/SDC/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://recoderchris.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"软错误","slug":"软错误","permalink":"https://recoderchris.github.io/tags/%E8%BD%AF%E9%94%99%E8%AF%AF/"},{"name":"2021","slug":"2021","permalink":"https://recoderchris.github.io/tags/2021/"},{"name":"TPDS","slug":"TPDS","permalink":"https://recoderchris.github.io/tags/TPDS/"}]},{"title":"SDC调研：Meta的两篇论文","date":"2023-02-06T02:07:35.000Z","path":"2023/02/06/Meta关于SDC的项目基金和已有的研究成果调研/","text":"背景Meta的服务(facebook, instagram, whatsapp, messengers)都依赖于数据中心的服务。 然而，静默数据错误(SDC)无法被大型系统所发现，在硬件层面无法被捕获，有可能会随着软硬件栈一直传播，最终形成应用层面的数据损失。这些损失可能需要数个月来修复，是大型基础计算设施中潜在的问题。以下在数据中心中出现的重大事故都与SDC问题相关： AWS S3 因 bit corruption 造成 36 小时的服务中断 Facebook 遇到 10%-15% 的图片无法访问 (48 小时) Netflix 宕机超过 3 天 潜在研究方向我们固然可以执行非常严厉的计划来避免 SDC 问题，然而无论多么精巧的设计都不能 100% 避免问题的发生，而且会急剧降低系统的整体性能。这就要求系统设计者学会在性能与可靠性之间做工程上的平衡。 针对以上前沿研究问题，Meta的系统和基础架构实验室已经开展了大量的工作并运用于云服务场景中以保证服务交付的准确性。经过多年的研究，Meta认为解决SDC问题有以下四个方向： 从**计算架构(Architecture)**层面处理SDC问题 架构层面上处理和转移SDC的方法，例如enhanced compute block ECC机制 自测试(self-test)的架构模块和模式，例如lockstep computing, checkpointing和redundant computing，这些方法都需要评估计算成本和性能代价 新颖的处理计算和内存错误的架构解决方案，包括但不仅限于增强传统的RAS架构。 从**分布式计算(Distributed Computing)**层面处理SDC的传播 遏制SDC传播的分布式计算弹性模型和解决方案 跨越多个子系统的错误检测能力 分布式规模的错误控制和测试机制 自测试SDC的分布式系统架构和恢复方案 从**软件(Software)**层面提供弹性服务 软件层面实现对SDC的弹性，例如冗余机制、概率和算法的容错机制 实现抗SDC的通用计算和数据搬运库 针对SDC的实时检测和遏制软件方法(需要评估计算成本和性能开销) 从过去的SDC中归纳SDC解决算法 从**硅设计(Silicon Design)**层面提供更可靠的硬件工艺 面向SDC问题，优化硅设计和制造策略 用于硅制造过程的进阶模拟、仿真和测试策略 硅测试的覆盖率评估、硅模块内发生故障的概率评估模型 用于SDC检测的生产过程中的测试例程开发 硅模块使用过程中逐渐衰退的模型和评估机制 Facebook在大规模集群中对SDC问题的理解以下内容来自论文《Silent Data Corruptions at Scale》(Arxiv) @Facebook。 补充背景以往的工作往往研究由于辐射或者合成错误注入产生的软错误问题，Meta的研究则注意到，由于设备的特性，SDC可能会发生并且大规模重复，这种SDC是可复现、非瞬态的。此外，在之前的错误注入模型的研究中，CPU的SDC概率被定为到百万分之一的几率级别，而在真实场景下，由于CPU功能模块中为了性能往往采用最小纠错机制，CPU SDC的概率要比预计高几个数量级。 产生缺陷的原因设备缺陷(Device Errors)在生产和设计阶段，设备本身有可能会有潜在的缺陷： 有些设计有可能有corner case。例如，在某个特定的功耗状态下管理cache控制器的模块，其功能会受到限制，有可能导致设备运行被卡住或者产生功能上发生错误； 在CPU布局布线期间，不能确定信号的到达时间，有可能导致错误的位翻转。例如timing path error 制造过程中，有可能所有的晶体管的蚀刻不够可靠，使得晶体管没有相同的峰值工作电压或功率阈值，各个设备的模块特点不同，导致制造上的错误。 早期故障(Early Life Failures)有些故障在生产过程中就被发现了，有些故障要等到硬件真正运行服务的过程中才会出现。根据晶体管内部缺陷的类型，故障可能会在运行前几周、几个月或预期设备寿命结束前的任何时间出现。 这些故障全部被归类为早期故障(Early Life Failures)。 设备老化(Degradation)随着频繁的使用，设备会逐渐老化。频繁使用的计算部分比 CPU 的其他部分老化的更快。与早期故障相比，这些由于设备老化而产生的故障并不常见，但仍有相关的例子，例如针对 DDR4 内存的RowHammer攻击。 芯片内部使用纠错机制(ECC)，可以防止设备内部性能下降。 晚期磨损(End-of-Life Wear-Out)当设备在现场服务工作负载一段时间后，超出其额定寿命，整个硅开始出现磨损，这在大多数组件中都可以观察到。 Case Study：应用层看SDC造成的影响Facebook中有大量不同类型的应用。我们以查询设施为例，最基本的查询基础设施是用来获取并执行SQL查询的设施，例如Spark, Presto, Hive等。下面以spark为例来描述SDC会给应用带来什么样的影响。 Spark 在Spark架构中，数据集被分为多个部分，这种数据集叫做弹性分布式数据集(Resilient Distributed Dataset, RDD)，每个数据集是单独并行执行的。执行过程是每个worker node上会分布有几个RDD块，每个worker首先做map，然后在shuffle reduce阶段将结果进行综合，最后再对用户提供请求的结果。 FaceBook解压缩应用FaceBook使用Spark进行压缩。这里，我们主要讨论解压缩的部分。当解压缩请求运行时，多组压缩文件会被输入到解压缩流水线中。在解压缩之前，系统会检查压缩文件的大小看是否大于0。如果结果大于0，才会执行解压缩。 在Spark中，解压缩流水线会提供文件的尺寸作为解压缩算法的输入，算法将执行Scala库的幂函数。有趣的是，FB在日常维护中发现了这样一个case study：幂函数会对一个已知具有非零大小的压缩文件返回0值。由于文件大小为0，因此这个文件不会被解压，这意味着随机丢失了一些文件。接下来，为压缩文件保留着k-v对的应用会发现这个错误，并且注意到此错误已经不可还原了，使得应用程序出错。 对以上问题做debug所有工程团队用日志记录下每一个worker的每一步的结果，并复现以上的错误→从日志中锁定出错机器→单机上复现错误→锁定错误只在某一核心上被某一组特定值触发→scala无法使用GDB调试，但可以用JVM兼容JAVA字节码 工具为了找出根本原因，Meta团队希望在不改变复现实验的含义的情况下，将编程语言从Scala转换为Java，再转换为JAVA字节码，最终到达指令级别来再通过GDB调试，以锁定错误出现的范围。但是java是即时编译的，并不能深入到指令级别，所以还需要一个提前的编译器编译出这些指令；或者需要一个探测器，可以在执行JAVA字节码时提供已经执行的二进制指令。 语言转换：Scala Compiler(scalac)，转换后可以生成交叉编译的java类型文件，可以当做java字节码 提前(ahead-of-time)编译器：GCJ，可以将java字节码转换成对象文件和二进制码，二进制码可以用GDB来debug。然而这个工具已经很久没有维护了，其他也没有更好的编译器工具。 **探测器(probe)**：JAVA提供+printassembly选项，用HotSpot追踪可以打印出已经运行出的汇编代码。 通过以上三个工具实现了GDB对代码进行debug。但是出来的都是汇编代码，且数量非常大(430K)，为了定位到错误的汇编代码，本文通过先将相关的函数筛选出来，再进行反向工程，实现对错误的定位。 很好的一些调试经验(略过了，太工程，大部分谷歌翻译了) 绝对地址引用：将绝对地址留在代码中跳转会导致分段错误。如果发现汇编的该部分对再现性没有依赖性，则最好消除绝对地址引用。 意外的分支：如果意外的分支和跳转调用没有被映射，代码会因分段错误而崩溃。最好限制复现器的可变性。 外部库引用：建议最好不要依赖外部库。 编译器优化：高性能代码具有多次编译器优化功能，观察数学方程式的优化有助于理解复制器所需的关键组件。 在逐步执行汇编指令时，优化可能不直观。 冗余指令：最好消除冗余指令，例如stub指令 输入&#x2F;输出寄存器：我们需要为关键指令识别数据输入和结果寄存器。识别后，必须添加额外的指令来提供用户输入、获得结果。 这实现了稳定的reproducer代码，并能够识别SDC的数据依赖性。 管理堆栈帧：独立的Reproducer需要适当地管理堆栈帧。 管理堆栈帧中的事务以防止缓冲区溢出或下溢对于稳定性至关重要。 没有堆栈框架，复制器代码无法管理基于堆栈的请求或函数调用。 内存偏移量引用：寄存器通常在指令中使用内存偏移量。 必须适当地初始化偏移量。 如果未计算和初始化偏移量，我们将遇到由于未初始化数据而导致的分段错误或复制器损坏。 特殊功能单元：需要监控特殊功能单元（如 ALU、DSP、FPU、AVX 等）的事务，它们会带来近似值。 此外，特殊功能单元利用不同的位宽、特殊功能寄存器和堆栈结构。 主框架：如果没有合适的主框架和功能框架，一个独立的reproducer是不完整的。 这使得代码可执行。 通过逆向工程，可以获得一个更简单的reproducer代码，之后通过GDB可以获得导致错误的指令，最终锁定在60行的汇编代码中。 重新审视应用的错误此后，本文注意到具有不同精度的不正确值，结果不尽相同。因此，应用程序可能解压缩了大小不正确的文件，并且将文件在没有在EoF终止符的时候下被错误截断。 这会导致文件节点悬空、数据丢失等无法跟踪的错误。 因为复杂的数据依赖以及数据的输入，如果无法没有复现代码，这种数据损坏几乎不可能被检测并溯源，尤其是在集群拥有数十万台机器、每秒执行几百万次计算的情况下。因此，以上的方法可以更快地溯源集群内SDC的根本原因。 对抗SDC的硬件方法我们观察到，在大规模基础设施中，SDC并不是局限于百万分之一概率的罕见事件。 这些错误是系统性的，不像其他故障模式那样容易理解。以下几种硬件方法可以降低处理器内的软错误率，对SDC也有效： 保护数据路径：使用ECC增强设备内的块，保护数据路径，提高设备的弹性。 专用的筛选模式：在制造流程中，设计专用的筛选和测试模式 了解大规模下SDC的行为：与大规模使用设备的客户密切合作，了解和评估SDC的影响。 研究发生率、生产故障时间、对频率、电压和环境条件的依赖性，有助于深入了解 SDC 的表现形式。 架构优先级：将来架构选择中，会优先考虑防止SDC的架构。 探测SDC的方法(不增加其他额外开销)为了探测到SDC，我们需要额外的机器来进行计算，之后与参考值比较结果。以下三种方法可以实现对SDC的探测： 找机会找机会利用处于维护状态的机器，并使用随机数据输入，执行指令级准确性验证。 这里的挑战在于其覆盖范围主要取决于机器有机会处于维护状态的频率。 在大型的集群中，我们并不希望有很大比例的机器处于这些状态。 周期性实施一个调度程序，定期监视机器的SDC覆盖率，然后根据定期计时器安排机器进行测试。这种方案的的开销很高。 对生产友好的方案当测试可以优化为最小的大小和运行时间时，可以使测试指令与机器上的工作负载同时执行。 结果被发送到收集器以通知机器的通过或失败状态。 此方法需要与工作负载密切配合，以免对生产工作负载产生任何不利影响。 软件容错机制为了处理静默错误，我们需要重新考虑基础架构软件设计理念和软件抽象的鲁棒性。 冗余机制防止应用程序级故障的更好方法是实施软件级冗余，并定期验证正在计算的数据在多个检查点是否准确。在将这些方法应用于大规模数据中心时，要考虑精确计算的成本。 冗余的代价对资源有着直接的影响：架构越冗余，重复资源池的需求就越大。 但是冗余为应用程序提供了容错的概率。 容错库将容错机制添加到 PyTorch 等知名开源库中将极大地帮助应用程序防止暴露于SDC。 构建容错的算法会增加应用程序的额外开销。因此，如果在性能下降可忽略不计的情况下，这一点可以被实现。 这项工作需要SDC研究社区和软件库社区之间的密切合作。 Facebook检测SDC问题的方法以下内容来自论文《Detecting silent data corruptions in the wild》(Arxiv) @Facebook。 硅测试流程在投入使用之前，基于硅的电子设备要经历不同的开发阶段。因此，我们要了解不同开发阶段所使用的测试策略，以理解集群范围内的与测试有关的开销，由此了解为什么测试是一件很难的事情。测试流程看重三点：测试量、测试时间、在该阶段出错产生的影响。 设计和验证(Design and Verification)采用模拟和仿真(Simulation and Emulation)的手段来进行方案的测试。测试的时间会很长，但是由于方案不断改变、新的器件会加入，所以测试周期一般会很短。在该阶段出错的代价相对来说是很低的 硅上验证(Post Silicon Validation)此阶段产生少量的样本进行验证。与之前一个阶段相比，设计加入了生产过程的变量。从开销上来说，这一阶段的验证会引入生产的开销。如果出错，需要对原始方案推倒重新设计，此外，在真实电路上开展测试的测试开销也很大。通过测试的方案被视为可以进行大规模生产。 生产厂商测试(Manufacturer testing)大规模生产之后，每个设备将用更加高级的测试设备进行自动测试。测试时间对生产通量有明显的影响，测试总量也从之前的几百个上升到上百万的量级。测试的开销随着数量也线性扩展。在这个阶段如果出错，开销会更大，往往导致重新设计或者重新生产该芯片。 集成测试这一阶段设备被运送到终端消费者手中，消费者用此设备集成到自己的开发环境中，集成阶段往往由集成者来协调。在这一阶段，需要跟其他不同的设备相配合，测试的复杂度也升高了；此外，测试的开销也从单设备到多种设备、多种配置的综合测试。此阶段出错，可能会导致不同的机架重新组装或者重新安装。 基础设施引入测试这一阶段主要是将机器接入网络，进行应用层面的测试。往往要持续几个小时到一天的时间。由于故障的来源多，所以锁定错误要更难一些。 基础设施集群测试正常的测试流程到上面就结束了。但是因为有SDC，如果不运行某个特定的测试程序是找不到SDC问题，以保护基础架构上运行的应用的。因此，按期进行检查是很有必要的。这种测试所需要花费的开销会更大，因为需要在保证程序正常运行的情况下对程序进行复杂的编排和调度。 此外，由于硬件的复杂度和配置的复杂度，分类和溯源错误是很昂贵的。因此，需要花费比较昂贵的开销，采用更多高级的方法来探测SDC。 SDC为什么是一个很难的问题？SDC可能的来源： 数据相关：SDC有可能天然与数据相关，也就是说这个CPU坏了，有可能大部分的计算还是正确的，但是就是一小部分是错误的。这使得测试的空间非常大。 电气因素：改变的电压、频率和电流会引起更多的错误，虽然在某一组电气配置下结果对了，但是其他情况不保证。这也使得测试空间非常大。 环境因素：地理位置的差异也会加速SDC问题的出现，这与温度、湿度都有很强的相关性。在大型集群中，也有可能因为workload不均匀一些机器温度高，使得某些计算中心结果和其他不一样。 寿命因素：随着时间，硅片的性能和可靠性也会改变。此外，SDC问题可能跟现有模型的预测有出入。因此今天计算正确，明天就不一定正确了。 从以上四点，本文总结保护集群以对抗SDC的唯一方法是通过不断改进的测试例程和高级测试模式生成来反复测试基础设施。 基础设施集群测试的方法(Infrastructure Fleet Testing)两个主要的测试方法： 停产测试(Out-of-production Testing) 不停产测试(In-production Testing) 停产测试(Out-of-production Testing) 停产测试是指让机器接受一组固定特征的输入，将其输出与已知参考值进行比较的过程。这种测试往往在机器没有执行生产负载的时候执行，并且测试要经历不同的温度、电压、机器条件和地域环境等复杂条件。 测试的特征往往是根据生产经验以及对硅架构本身的理解来生成的，以匹配常见的一些缺陷。一般来说，在大型基础设施中，总是会有一部分机器处于维护状态，在维护开始之前，机器上的负载会被迁移下来，这叫做draining phase。之后会进行维护，例如固件升级、内核升级、环境配置、修理等措施，之后再重新将工作负载迁移回来。 之后进行停产测试：用于停产测试的工具是Meta开发的Fleetscanner。Fleetscanner会找机会识别那些进入和退出维护状态的机器，并且使已经完成维护的机器进入停产测试SDC阶段。在所有情况下，根据可用的测试时间、识别的机器类型，fleetscanner会运行优化的测试，并提供设备对敏感的架构代码路径的响应快照，并验证计算是否准确。此时，大量的机器相关的参数会被瞬间捕捉到，以在分析过程中理解设备出错的具体条件。任何被鉴别为出SDC错误的机器会被放进quarantine pool中，以待进一步的观察和测试。 不停产测试(In-production Testing)不停产测试是指在集群内机器仍然运行工作负载的情况下，同时进行测试。如果不对测试例程和工作负载有细致的了解，则很难实现这一点。Meta实现了一种叫做ripple的测试方法，与工作负载同时存在，并且每次实现毫秒级别的测试时长。在停产测试中使用的测试序列被修改，以通过ripple测试。 影子测试 Meta实施了可以跨多组工作负载的ripple，并且精心设计了ripple测试架构，以防止整个集群的错误。 影子测试的一个主要挑战是实现托管。 基于工作负载的扩展，测试规模必须缩小。 对于 Meta 的每种类型的工作负载，确定了缩放因子的评估过程。此外，Meta还建立了与测试相关的开销分析，每种工作负载类型的托管都会提供开销，该工具的目标是将其开销降至特定阈值以下。通过反复试验，我们建立了控制结构和保障措施，以便为不同的工作负载启用不同的选项，然后将解决方案扩展到整个集群。 持续不停产持续不停产的纠错机制始终处于开启状态，只有它运行的规模是通过集群内的配置动态控制的。 这种方法在查找需要对相同数据输入进行数千次迭代的缺陷，以及识别正在退化的设备等方面非常有效。 在几周内，通过测试随机化和缺陷模式匹配，可以将设备中识别的新签名扩展到整个设备群。 这种方法在识别硅过渡缺陷方面也非常有效。 效果对比 根据三年的真实测试对比两种策略。 使用 ripple 可以在 15 天内完成 70% 的常见覆盖检测，Fleetscanner 在 6 个月内将覆盖范围扩大到剩余的 23% 独特的 7% 覆盖率是通过集群内重复的ripple实例实现的。 通过不断地重新审视和评估这些覆盖率指标，可以知道围绕测试向量、测试节奏和测试运行时间的集群范围内的测试策略。 对于不同类型的缺陷，覆盖率会有所不同。","link":"","tags":[{"name":"容错","slug":"容错","permalink":"https://recoderchris.github.io/tags/%E5%AE%B9%E9%94%99/"},{"name":"SDC","slug":"SDC","permalink":"https://recoderchris.github.io/tags/SDC/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://recoderchris.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"软错误","slug":"软错误","permalink":"https://recoderchris.github.io/tags/%E8%BD%AF%E9%94%99%E8%AF%AF/"},{"name":"2021","slug":"2021","permalink":"https://recoderchris.github.io/tags/2021/"}]},{"title":"(HPCA06)从体系结构角度看软错误问题","date":"2023-02-04T13:34:34.000Z","path":"2023/02/04/软错误问题/","text":"以下内容来自HPCA’06的论文《The Soft Error Problem: An Architectural Perspective》。 背景知识什么是软错误高能粒子(e.g. 宇宙射线中的中子和封装材料中的α粒子)通过半导体设备(电路)时，会在其上产生电子空穴对(electron-hole pairs)，这会可能会导致瞬态错误(Transient Fault)。具体来说，电子空穴对会对晶体管的源(source)和扩散节点充电，如果充电量到达一定的阈值，会使得设备上某个组件(e.g. SRAM、锁存器、门电路)的逻辑状态发生改变，最终使得整个电路的运行结果产生逻辑错误，这种因为瞬态错误继而产生的运行错误被称为**软错误(soft error)**。 1PS: 与此相对应，硬错误(hard error)是指电路原件发生破坏，错误无法在短时间内修正的错误。个人理解是：软错误相对于硬错误来说是一种逻辑错误，而不是真实硬件发生了错误。软错误在接下来也许很难复现。 一般来说，每个电子元器件器件的纯软错误率(raw error rate)是一个常数。随着工艺水平的提升，单位面积的电路中将会集成更多的电子元器件，因而整个电路的纯软错误率线性增长。为了降低纯软错误率，一些DRAM厂商通过减缓单位电容的提升、降低供电电压等措施来降低每比特的软错误率，以应对工艺迭代会造成的软错误率提升。 软错误：从工业界到学术界工业界中亟待解决的因为软错误而产生的问题： 在芯片设计中，厂商希望能够了解软错误会对其设计产生多大的影响 希望能够从现有的技术中选择一种合适的策略来降低软错误产生的影响，以达到通过最小代价换取其可靠性指标的目的。 而学术界要解决以下的具体问题： 开发更好的设计框架、分析技术和软工具，以对软错误造成的系统影响产生更直观的理解和更量化的测量 探索和刻画软错误避免、探测和恢复的技术，在合理的性能、功耗、面积和复杂度要求下，满足对不同可靠性指标的要求 单比特软错误的分类SDC &amp; DUE **SDC(Silent Data Corruption，静默数据错误)**：没有被探测到、没有被修复，且对最终结果产生了影响的软错误。 **DUE(Detected Unrecoverable Error，被探测到且无法修复错误)**：被探测到了，但是无法被修复的错误。 目前，业界认为软错误率为SDC和DUE之和。DUE错误因为无法修正，所以它并不会影响整体的错误率。对抗DUE错误的最基本的对抗办法是fail-stop(重新运行)，以保证最后结果是正确的，但是它实际上并没有降低错误率。 DUE有两种分类： 第一种分类：会对最终结果产生影响的被称为true DUE，不会产生影响的被成为false DUE。保守的系统会对所有的DUE错误进行处理，一些系统则会分辨false DUE，例如错误选择路径的指令，来分门别类进行处理。 另一种分类：根据重新运行方式被分为process-kill和system-kill的DUE。所谓的process-kill是指一些DUE(e.g. 奇偶位校验错误)产生后，操作系统会隔离开这个错误，锁定一组出错的进程将它们杀死，保留其他进程正常运行，这种DUE被称为process-kill DUE；而另一种DUE是只能将整个系统关闭并重启才可以修复的错误，被称为system-kill DUE。 衡量软错误的单位：FIT和MTTF **FIT(failure in time)**：是指在109小时内产生的错误次数。SDC和DUE都可以用它来量化，FIT具有可加性，例如芯片的FIT可以用它上面所有组件的FIT求和得到。SDC和DUE的FIT数值和是整个芯片或系统的SER(soft error rate，软错误率)。 **MTTF(mean time to failure)**：是FIT的倒数，一种更加直观的展示。含义是经过多久系统会发生一次软错误。例如：1FIT&#x3D;114 years 一般来说，厂商都会在推出产品前规定自己产品的软错误率预算。例如IBM的power4宣称其SDC MTTF&#x3D;1000yrs，process-kill DUE MTTF&#x3D;10yrs，system-kill DUE MTTF&#x3D;25yrs。有更好的错误检测机制的系统，其SDC FIT会越低，但是DUE会更高。只有同时具备良好的检测(detection)和恢复(recovery)机制的系统，SDC和DUE FIT都会更低，使得SER会更低。 计算或估计SDC和DUE FIT芯片或系统设计团队要面临的一大问题是：设计出来的产品能否满足其软错误率预算的要求。当然，最准确的测量设计的软错误率的方法应该是这样的：使用加速中子或者放射性阿尔法粒子对真实电路进行实验。但是这种方法的实验代价太大，且需要将产品研制出来之后再测试。这种方法显然既耗时间，又不经济，不符合在芯片设计阶段的要求。 要计算或者估计设计的软错误率，目前普遍采用的是建模和计算的思想。首先，软错误率为SDC FIT和DUE FIT之和，之后再将整个系统或芯片的FIT拆解成每个组件的FIT。而每个组件的FIT又可以分为以下两个部分： 原始设备错误率(raw circuit error, 指瞬态错误能够导致组件状态转变的可能性) 体系结构脆弱因子(AVF, 指这个组件的状态变化，能够产生架构层面上可见的SDC&#x2F;DUE的可能性) 由此可见，计算设计的软错误率需要计算原始设备错误率和体系结构脆弱因子两项。 原始设备错误率每个组件的原始设备错误率由两个因素来决定：环境中的粒子流量和由工艺和实现决定的底层电路错误率。 粒子流量(particle flux)错误率基本和环境中的粒子流量成线性关系。环境中的粒子可以通过施加适当的屏蔽机制来实现一定程度的屏蔽，但是一般来说效果并不好。(需要很厚的混凝土隔离，不好实现)此外，随着海拔高度升高，粒子流量也会上升。 底层电路错误率(circuit error rate)电路错误率又由两个因素来决定：原始电路错误率和时间脆弱性因子(TVF, time vulnerability factor)。 原始电路错误率：指的是特定的电路单元会发生比特反转的可能性。这个跟比特反转的充电量Qcrit有关系，而这个数值由电路的电容和电压决定。一般来说，为了估算原始电路错误率，可以通过在不同时间点模拟电路单元(cell)的所有节点上的所有尺度的电流脉冲来计算原始错误率。但是这个花费的时间复杂度太高。因此，对于全芯片模拟，通常我们使用近似模型或蒙特卡洛模拟技术。 TVF：它是指在一个周期内一个比特反转会被捕获到的概率。例如，对于DRAM来说，因为它每个周期都会刷新一次，所以其被捕捉到的概率是100%；对于锁存器，只有在其内部保存数据的时候电路翻转才会被捕捉到，故概率大概是50%；对于一些静态逻辑电路，例如NAND电路，它只有在其前向电路(例如：前向电路中有锁存器)捕捉到这一变化时才有效。 123例子：计算原始设备利用率一般假定FIT/bit在0.001~0.01之间(原始电路错误率)，我们假定最小值0.001。TVF=50%，目标系统有4个CPU，SDC FIT预算为114FIT，我们可以算出每个处理器中最多有57,000(=114FIT/(0.001FIT/bit*0.5TVF*4CPU))个不受保护的锁存器。 SDC AVF SDC AVF：一个比特反转真正能够导致系统实质性执行错误的可能性，因为这个反转既没有被处理，也没有被探测到。 比特反转并不一定造成实质性执行错误：例如，如果分支预测的寄存器发生比特反转，不会影响程序的执行结果(SDC AVF&#x3D;0%)；而如果程序计数器的寄存器发生比特反转，程序大概率会被影响(SDC AVF&#x3D;100%)；指令队列中的寄存器比特反转就不一定了，如果里面存储的是错误路径的指令，那么SDC AVF很低；而如果是关键路径，那么SDC AVF就很高了。 ACE(architecturally correct execution)：ACE代表任何一种能够向用户产生正确系统执行结果的执行。 ACE bit：是指其中包含的信息一旦改变，将会影响程序的最终结果。un-ACE bit反之。 一个存储单元的SDC AVF是其中ACE bit的占比。如果一个程序执行了1000万个周期，其中的一个存储单元包含100万个周期的ACE位，则该单元的SDC AVF为10%。一个设计的SDC AVF是所有单元SDC AVF的总和。 DUE AVF DUE AVF是指比特反转会导致DUE的概率。它是true DUE和false DUE的总和。 True DUE AVF实际上是SDC AVF中被探测到的那部分，它在数值上等于老的SDC AVF 计算SDC和DUE AVF有三种方法：统计性错误注入、分析模型和性能模型(模拟器)。 统计性错误注入(Statistical Fault Injection, SFI) SFI是一种历经时间检验的测量脆弱性参数的方法 方法：在被研究的RTL设计结构中引入比特反转(时间空间随机)，之后运行设计，比较没有错误的模型和当前模型的体系结构状态。在运行几个模拟cycle之后，如果对比没有差异，说明错误潜伏在处理器中，或者已经被掩盖了。后者可以通过继续比较微结构状态来说明。此架构的AVF就是结果差异数量和比特反转数量的比值。（Architectural state includes main memory, architectural registers, and the program counter. Architectural state is defined by the instruction set architecture and can be manipulated by the programmer using instructions.） 优点：有力、不需要对处理器内部设计了解。 缺点：只能在详细的模型(RTL级，需要建模所有的比特)生效，对于每一个注入错误比特，需要上万cycle的测试，相当耗费时间；有错误和无错误的模型之间的不匹配不一定意味着存在错误，因为体系结构状态实际上可能包含非ACE位，例如动态死寄存器值。 分析模型 场景：比特流未经修改且没有重复地流经电路 Little’s Law: N &#x3D; B x L N – 结构中的平均比特数量 B – 每个周期进入结构的平均比特带宽 L – 每个比特通过结构的平均延迟 分析模型：$$\\frac{B_{ace}\\times L_{ace}}{number,of,bits,in,structure}$$ 举例：对于指令队列，Bace是 IPC（每周期指令数）乘以每条指令的 ACE 位数。 Lace 是指令在指令队列中的驻留周期。 当性能模型和 RTL 都不可用时，此方法在设计的早期阶段很有用。 性能模型 基本思想：识别流经机器的比特哪些是 ACE状态，哪些不是 ACE状态。 根据定义，每个比特位包含 ACE 状态的时间占比是位的 AVF，此过程被称为寿命分析。 主要挑战：确定每个位寿命的un-ACE 部分。导致un-ACE 状态的例子(在指令中)有dynamically dead&#x2F;wrong-path&#x2F;falsely predicted instruction。因而生命周期分析需要深入了解架构和微架构。 优势：与 SFI 不同，性能模型中的 ACE 分析要快得多，因为可以在一个实验中计算大量处理器结构的 AVF。 此外，性能模型可以实际运行数千万个周期，此它可以提供比 SFI 更高的准确性。 减小软错误率的方法以上只是介绍了如何估计一个设计的软错误率。而真正要减少软错误率，可以从以下三个方面入手：制造工艺、电路层面和架构层面。 处理工艺层面 方案：绝缘体上硅 (silicon-on-insulator, SOI)。 原理：因为其硅层薄的多，SOI 器件从 alpha 或中子粒子撞击中收集的电荷较少。 效果或优势：SOI 工艺可以使 SRAM 设备的 SER 降低 5 倍。(IBM) 缺点：尚不清楚是否会从 SOI 锁存器和逻辑器件中获得类似的 SER 降低；SOI 芯片的批量生产仍然是一个挑战。 电路层面 方案：调整设备参数、创建抗辐射（或抗辐射）单元。 原理：增加设备的电容和&#x2F;或电源电压，这两者都会提高 Qcrit，来降低软错误率； 抗辐射单元(cell)可能包含冗余状态，可以用来从软错误中恢复。 缺点：抗辐射单元会带来显着的面积和功耗开销。 架构层面架构解决方案可能比电路级解决方案更有效： 错误的【定义】通常存在于体系结构中（例如，对分支预测器的攻击不会导致微处理器中出现错误）。 典型的架构层面解决方案（例如奇偶校验或 ECC）的开销通常可以分摊到大量的位上。例如，ECC 的开销为每 64 位数据额外多出8位（即 13%），而抗辐射单元可能有 30-100% 的面积损失 微观层面(micro solution) 奇偶校验(parity)：奇偶校验可以检测任何单比特错误，但只能检测，不能修正。 受奇偶校验保护的位，通常具有SDC AVF&#x3D;0，但DUE AVF不等于0。 但是，奇偶校验保护结构的 DUE AVF 可以通过架构知识减少到零。 例如，受保护的直写缓存可以使奇偶校验错误的块无效，并从较低级别的缓存中重新获取正确的块。 SECDED ECC(single error correct, double error detected)：通常用于处理器高速缓存，可以纠正所有单比特错误并检测所有双比特错误，为单比特错误提供零SDC 和 DUE AVF。 ECC 可以inline或out-of-band实现：inline ECC 需要在读取返回数据之前计算并验证 ECC 代码是否正确，这通常会在处理器流水线中产生一个或多个额外的周期；out-of-band ECC 检查允许处理器继续读取数据，如果 ECC 检查检测到错误，读取不正确数据的指令重新提交，缓存数据被更正。 π 比特：π 比特是一种错误传播机制，可减少false DUE。 检测到错误后，不会立即发出错误信号，而是将错误发布在π位中并传播，直到有更多有价值的信息出现。 例如，在奇偶校验中，不会保护的寄存器文件中直接引发错误，而是可以通过在读取特定寄存器的指令时设置π位来发布错误。如果确定有问题的指令在错误的路径上，则忽略π位，避免false DUE 事件的发生。 宏观层面(macro solution)微观层面的方法可能需要大量的面积和设计工作负担。 因此，在某些情况下，使用 CPU 或线程进行故障检测可能会更简单。两种广泛的故障检测解决方案包括流水线的逐周期锁步(lockstepping) 和**冗余多线程 (redundant multithreading, RMT)**。 逐周期锁步： 在逐周期锁步中，同一的程序在相同的流水线上运行，每个周期都会检查二者的输出是否一致。 RMT：在指令的提交点检查选定的指令的输出是否匹配。 与锁步不同，RMT 并不需要两个线程每个周期进行同步。 以上方法降低了 SDC 率，但增加了 DUE 率。 降低处理器的 DUE 率需要通过硬件或软件进行错误恢复实现。从检测到的错误中恢复需要识别有问题的处理器并保持可以启动恢复的正确状态。 当外部检查器检测到错误时，可以从内部错误信号中识别有问题的处理器；或者可以定期检查处理器的状态，并在错误回滚时从检查点重启流水线或线程。 未来方向 计算不同架构的 SDC 和 DUE AVF：需要详细的生命周期分析和潜在的新技术，以识别处理器结构中的 ACE 和非 ACE 组件。 适用于不同处理器结构的AVF缩减技术 保护数据通过的微架构状态：现代处理器芯片既包含处理器内核，也包含系统组件，例如内存控制器和路由器。 保护流经“非核心”部分的数据可能并不难，我们可以通过在流水线中创建数据的位置，生成错误保护位提供端到端的错误保护，并让其保持不变地流动，直到数据被使用。 然而，保护数据通过的微架构的状态可能需要进一步研究。 RMT 的软件版本：锁步基本上是一个硬件概念，而 RMT 可以在硬件或软件中实现。与之前的软件故障检测实施相比，RMT 模型允许设计人员减少必要的软件检查次数。 此外，软件无法完全了解硬件，因此硬件可能必须有选择地去保护RMT无法涵盖的一些结构，这涉及软硬件协同。 了解和描述软错误与功率的权衡关系： 当电源电压降低时，软错误率会急剧上升。 二者如何权衡是下一步要解决的一个问题。 来自其他问题的软错误：例如电源噪声、耦合等。这需要详细了解不同的故障模型，但关于软错误的许多定义可以被转移到这些类型的故障中。","link":"","tags":[{"name":"容错","slug":"容错","permalink":"https://recoderchris.github.io/tags/%E5%AE%B9%E9%94%99/"},{"name":"SDC","slug":"SDC","permalink":"https://recoderchris.github.io/tags/SDC/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://recoderchris.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"软错误","slug":"软错误","permalink":"https://recoderchris.github.io/tags/%E8%BD%AF%E9%94%99%E8%AF%AF/"},{"name":"Umich","slug":"Umich","permalink":"https://recoderchris.github.io/tags/Umich/"},{"name":"2006","slug":"2006","permalink":"https://recoderchris.github.io/tags/2006/"}]},{"title":"eBPF+CSD调研","date":"2022-07-11T14:15:15.000Z","path":"2022/07/11/eBPF/","text":"很多人认为融合eBPF技术会是未来计算型存储器**(Computational Storage,CSD)的一个重要发展方向。本文调研了eBPF技术的原理和应用场景**，并指出“Why eBPF+CSD”。此外，本文还调研了当下在CSD中使用eBPF技术的难点和可能的替代选项。 什么是eBPF技术？前身：BPF(Berkeley Package Filter)BPF背景：于1992年提出，当时unix操作系统提供了捕获数据包的设施以监控当前的网络情况。但是，网络监控程序(如tcpdump)处于用户态，数据包必须频繁地被从内核态被拷贝到用户态。因此，一些被称为【数据包过滤器】的内核代理被提出了，以尽早在内核就丢弃不想要的数据包，避免从操作系统内核向用户态复制其他对用户态程序无用的数据包，从而极大提高性能。BPF是其中一种。 图 经典的BPF BPF实现：用户态的进程可以提供一个过滤程序，BPF功能用对于BPF虚拟机机器语言的解释器来实现。 extended BPF: 从3.18版本开始，linux内核中提供了一种扩展的BPF虚拟机(eBPF)，可以被用于非网络相关的内核其他用途，比如附着在不同的tracepoint上获取内核运行的信息，eBPF也被windows操作系统所采用。 eBPF技术简介现代eBPF：eBPF现在已经不再是任何东西的缩写，而是一项单独的技术。它可以在不修改内核源代码或者加载内核模块的情况下，在特权上下文(如操作系统内核中)运行沙盒程序，被用来安全高效地拓展内核程序。可编程的部分直接添加到现有层中。 优势：由于内核具有监督、控制整个系统的特权，操作系统一直是实现可观察性、安全性和网络功能的理想场所。但是内核由于其核心作用和对稳定性和安全性的高要求，修改内核很难。eBPF则改变了这一点，并且由操作系统来保证其安全性和执行效率。 可编程性：因为eBPF虚拟机使用的是类似于汇编语言的指令，可编程性差。现在的编译器正在兼容高级语言生成BPF字节码。例如，LLVM在3.7版本开始支持BPF字节码作为后端输出。 eBPF的实现： 图 eBPF开发流程 eBPF技术现有的应用领域 网络（协议解析、转发逻辑） 跟踪和分析（可以同时跟踪内核和用户程序的执行，提供强大的解决内核问题的能力） 安全性（更好的保护系统，允许结合所有方面的可靠性） 传统存储（实现数据过滤） …… 图 eBPF面向的应用场景和技术栈 为什么说eBPF+CSD是一个重要的发展方向？当前CSD发展所目前面临的难点目前，CSD的可编程性仍然很差： CSD的设计没有统一的标准。由于不了解设备内部的复杂程度，且很难去对内部编程，探索硬件模型和在主机上统一集成接口非常困难； CSD没有标准的编程抽象、API或者编程模型。之前的工作往往都是选定编程模型，而不是让开发者自己来自定义编程以适应当前工作负载。 可编程性意味着可以动态、安全地运行用户提供的代码，能够方便的将用户需要的任务卸载到存储器上。而eBPF可以将用户定义的任务“注入”内核，刚好符合这样的要求；又因为eBPF有现有的工具链和库，CSD研究者们希望用eBPF来为CSD提供任务卸载。 为什么选择eBPF？ 不影响内核：CSD需要在主机上开发程序并让存储控制器执行它们，而不影响控制器上原有固件的执行；而使用eBPF技术可以将eBPF程序挂载到内核中，而无需修改内核。 架构无关：eBPF与架构无关。在计算型存储器中我们希望使用与硬件无关的指令集，而不是预先知道CSD上处理器的型号再来下载对应的代码(X86或ARM)。 想象一个可能的应用场景：假设我们要对压缩加密后的大型数据库表进行数据分析。首先，借助CSD的可编程部分，我们可以在离线阶段在CSD中定义一个通用的控制程序，例如将数据读取到CSD的内存缓冲区，并解压解密数据放入CSD上的一个本地位置；在线阶段用户可以通过eBPF自定义计算程序，对数据进行过滤，最后再将过滤后的数据传输到主机。这样可以通过自定义的方式，能够更好地贴合数据特征，进一步节省内存和带宽，比之前的方式灵活的多。 CSD与内核的相同点和不同点 相同点：eBPF指令集和工具链已经相对来说比较成熟。我们像kernel中一样地把 C 程序编译成eBPF 目标文件，就可以在CSD中使用 eBPF 生态中已有的东西。 不同点：eBPF发源于内核，而内核对 eBPF 程序允许执行的操作有非常多的限制。例如，eBPF 指令集是允许用户写无限循环的，但Linux内核中的虚拟机在检查时会拒绝该程序。这是由之前的应用场景导致的：因为内核在处理数据包的时候没有那么复杂的操作。但是在CSD的场景下，我们可能希望运行 eBPF 做计算，这就需要对一些复杂数据结构进行处理，要放宽原有的限制。 CSD+eBPF产生的研究性问题 如何让eBPF执行计算任务：eBPF目前的应用主要是一些计算复杂度低的控制类程序，且必须要通过现有的应用于Kernel场景的eBPF虚拟机进行验证。但计算程序更复杂，运行时间更长。因此，如何将eBPF应用到计算任务上，以使得程序运行效率接近基于目标硬件指令集的程序是目前eBPF开发人员关注的一个重要问题。 可能的方法：修改eBPF虚拟机定义的正确运行时限制、定义新的计算指令（跟CSD无关） 任务卸载：对于一般的大型计算任务，哪些工作负载卸载在CSD上会更有意义？我们如何为这些任务定义一个通用的 API 或框架？ 通信问题：在存储设备中的CPU往往算力较小，因此其需要辅有其他专用硬件来完成计算。eBPF程序与存储上其他设备的通信方式也是难点之一。 一个可能的eBPF+CSD prototype来自阿姆斯特丹自由大学的团队探索了**基于QEMU仿真ZNS，来实现eBPF+**CSD的一个prototype。(仍然在开发中，文档健全；官网给出运行的视频样例)(https://github.com/Dantali0n/OpenCSD)。我们可以通过这个项目去展望一下eBPF+CSD的设计： 图 技术报告封面 配置 QEMU：仿真Zone NameSpace SSD（ZNS）。 SPDK：一种与用户空间的存储设备接口（在本项目中就是指能够与QEMU仿真的ZNS）的技术。 uBPF(user-space BPF)：一种ebpf虚拟机。 图 ZCSD的工作流程 主机端 编写程序BPF程序：用户编写的BPF程序中应当包含所有需要在CSD上运行的API； 编译：Clang+LLVM编译生成bpf字节码； 格式转换：Bpftool转换将bpf字节码转换为要用户程序包含的头文件，其中包含有elf格式的字节码； 包含头文件：头文件包含在用户写的程序中，用户有了调用CSD上eBPF程序接口的能力 之后编译好的BPF程序可以通过用户写的程序连同NVMe API来使用了。 存储端 程序提交：用户程序以elf格式提交用户程序 虚拟机****执行：uBPF被用来执行BPF程序，提供BPF API的实现 取数据：BPF程序通过SPDK在底层的ZNS中取数据，ZNS返回的数据由驱动程序和SPDK处理。 自定义计算：BPF程序进行计算或过滤，将数据返回给用户程序。 用户接收数据：用户程序接收数据。 NVMe扩展了原有的NVMe指令集： 下载eBPF程序：以elf格式发送BPF程序； 返回处理数据：将eBPF程序的返回数据提取出来。 eBPF不是唯一的选择现有的一些讨论将eBPF视为对CSD进行卸载的主要方案，这一观点并没有仔细考虑其他的选项。https://arxiv.org/abs/2111.01947这篇论文从**定性**和**定量**的角度来综合比较了**eBPF**和**WebAssembly(另一种易于移植的、低层次的字节码，用于基于堆栈的****虚拟机****)**的区别，给出了他们对于这个问题的见解。 CSD的其他选择 eBPF：现在指允许在Linux内核总运行沙盒程序的技术的总称。但是我们在这里尤其对基于寄存器的eBPF字节码感兴趣。eBPF现在应用在网络包过滤以及系统监视等多种应用场景中。以下展示了用eBPF写I&#x2F;O tracer的工作过程：用户用C语言写一个I&#x2F;Otracer，然后用clang编译成eBPF字节码，这个字节码将会被libbpf加载进内核执行。虽然目前来看eBPF字节码常常被用于linux kernel的场景下，但是也有很多工作去尝试独立运行eBPF的字节码。 WebAssembly：WebAssembly是一易于移植的、低层次的字节码，用于基于堆栈的虚拟机。它是为在浏览器中安全高效的运行而设计的。已经有工具从python或C语言来生成WebAssembly的代码，为了在浏览器环境之外执行这些字节码，可以使用wasmtime&#x2F;wasmer&#x2F;GraalVM等带有JIT的虚拟机。 计算型存储器背后的思想是代码迁移，将处理直接卸载到存储设备中。过去的方案试图为特定类型的工作负载提供专用软硬件，而缺乏对通用计算卸载的讨论，例如用户可编程的、动态可卸载的计算。 分析目标通过定性和定量评估eBPF和WebAssembly两种卸载机制来重启关于通用计算任务卸载机制的讨论。具体来说是回答以下问题： 这两个卸载机制当前处于一个什么样的状态？ 二者的优缺点分别是什么？ 在计算型存储器的背景下怎么去改进这些两种机制？ 定性分析 安全性这里的安全性是指抵御人为错误的机制：如果卸载的bytecode里有bug，能发生的最坏结果是什么？ WebAssembly：卸载的代码会在一个隔离的内存空间中运行，并且默认是不允许访问文件系统。因此bug可能最差会引起CPU时钟周期的浪费，但是并不会在runtime之外造成什么影响。 eBPF：主要取决于验证器。Linux内核验证非常严谨，禁止很多类的循环和数据访问；而使用这样的内核进行数据处理显然不适用。新的验证器仍然待开发，因此还不能说eBPF的安全性如何。 工具链 开发工具：对于WebAssembly，有一系列叫做wabt(WebAssembly Binary ToolKit)的工具可以来检查和转换WebAssembly的二进制文件。对于eBPF，bpftool能够用来检查eBPF程序，但是本质上它与内核的使用绑定，所以在独立的场景下没法使用。Llvm-objdump对于ebpf来说是更好的选择。 虚拟机：如之前所提到的，WebAssembly有至少三种适合不同场景的虚拟机实现。虽然他们都有一些同样的特点例如JIT支持，但是他们也有很多独立的特征；但是eBPF却仍然还有很长的路要走。uBPF和rBPF都有JIT支持(仅x86_64)，但是他们仍然缺乏分析和调试等方面的功能。 兼容性这里的兼容性指重用现有生态中库的能力，任何外部依赖项(包括C库libc)都要被重新编译并静态链接。 WebAssembly：使用wasi-sdk进行编译，但是也有一些函数例如fork&#x2F;pthread无法build。 eBPF：没有wasi-sdk这样的工具，由于无法调用C库，所以大量现存的库也无法使用了；除此之外，由于clang -target bpf不支持一些种类的数值操作和浮点操作，一些数据类型也可能不支持，这主要是因为eBPF缺乏合适的指令让clang来生成。因此，我们并不知道这些操作将如何被eBPF来使用除非eBPF有重大的扩展。 可移植性由于二者都是字节码，所以都比较好移植 eBPF：并不是大小端独立的。ebpf的大小端依赖会影响他的移植 WebAssembly：总是用小端模式，如果host架构是大端的，runtime可以来负责转换 用户体验 编译：WebAssembly可以由多种语言产生，可以用两种方式(Emscripten和wasi-sdk)来编译进行C库支持。除此之外，支持链接时间优化、关闭系统C库、无main入口支持等选项，最后还可以对生成的code码来缩减大小；ebpf可以用clang的bpf选项来编译，但是实际上是对内核内部的应用进行编译的。 字节码检查：wabt工具链中有一个wasm2wat的工具，能够将二进制webassembly文件转换为可读的文本文件。也可以使用wasm-objdump进行反编译。ebpf虽然还没有正式的文本格式，如果ebpf二进制文件是由debugging信息编译成的，可以用交叉源代码查看反汇编的二进制文件。 语言不可知性 webassembly：可以用大量的源语言。但是实际上，源语言必须支持导出malloc()以分配buffer，并且在主机和虚拟机之间传递程序。 ebpf：目前只支持C语言为源语言。 定量分析内存占用：rbpf和ubpf接近原生表现 运行时间：实际计算所花费的时间，rBPF和uBPF表现非常好，以至于能够击败host上的binary。 总时间：rBPF和uBPF在x64架构上经常击败基于host的方式 讨论虽然eBPF虚拟机在定量分析中显示占有更少的内存、计算性能更好，但是作者从定性分析的角度，认为eBPF存在更多的缺陷，而webAssembly可能是更成熟、更容易上手的选择。 图 定量分析实验其中之一 图 对eBPF和WebAssembly定性分析的总结 下面是一些潜在的可能提升机会： webassembly：作为一个相当成熟的技术，仍然有以下改进方向 实现SIMD和多线程 提供与host数据共享的接口 解决安全问题 eBPF：根据前面的评估，eBPF在成为适合的数据处理工具之前还需要做很多工作 成熟的虚拟机，能够支持debug和性能分析 扩展指令集，以支持多种数字运算 明确定义允许操作的规范 与规范同步开发的可靠验证器 C库和其他系统服务的支持","link":"","tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://recoderchris.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"eBPF","slug":"eBPF","permalink":"https://recoderchris.github.io/tags/eBPF/"},{"name":"近存储计算","slug":"近存储计算","permalink":"https://recoderchris.github.io/tags/%E8%BF%91%E5%AD%98%E5%82%A8%E8%AE%A1%E7%AE%97/"},{"name":"操作系统","slug":"操作系统","permalink":"https://recoderchris.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"前沿系统","slug":"前沿系统","permalink":"https://recoderchris.github.io/tags/%E5%89%8D%E6%B2%BF%E7%B3%BB%E7%BB%9F/"}]},{"title":"图数据管理-课程笔记2","date":"2021-02-04T12:16:19.000Z","path":"2021/02/04/图数据管理笔记2/","text":"Network Properties and Random Graph ModelI. Key Network Properties Problem: How to measure a network? Answer: Using Network Properties. 1. Degree Distribution P(k)P(k) is the probability that a random chosen node has degree k. is number of nodes with degree k. Thus. 2. Path p, Average Distance and DiameterA path p is a sequence of nodes in which each node is linked to the next one. Shortest Path Distance: the number of edges along the shortest path connecting two nodes. Diameter: the maximum distance between any pair of nodes in a graph. That is, Average path length for a connected graph or a SCC graph is defined as: . In practice, we compute the only over the connected pairs of nodes. 3. Cluster Coefficient cA vertex’scluster coefficient c measures how a vertex’s neighbors are connected to each other. Assume as the number of edges between neighbors of vertex , and as the vertex degree. The cluster coefficient can be calculated as Globally, the Average clustering coefficient is . 4. ConnectivityTo show the connectivity of graph, one can calculate the size of the largest connected component in graph, BTW, largest component is also known as giant component. II. Measure Real-world Networks In this part, we use MSN network as an exaple to show some properties of real-world networks. 1. Degree Distribution Power law distribution: , where is a parameter whose value is typically between 2 and 3. The graph degree distribution is heavily skewed. 2. Clustering Coefficient Average Clustering Coefficient of Real Graph can be really big(0.1140) compared to the random graph. 3. Connected Components Nearly all of the vertices are in one largest(giant) connected component. 4. Diameter Average path length is 6.6. Besides, 90% of the nodes can be reached in &lt;8 hops. 5. Small World Effect(Six Degrees of Separation), 1967 A small-world network is a type of mathematical graph where most nodes are not neighbors of one another, but most nodes can be reached from every other by a small number of hops or steps. In mathematical format, assuming L is the distance between two randomly chosen nodes, and N is the number of nodes in a network, then we have . III. Graph Generation ModelThere are four kinds of Graph Generation Model. 1. Random Graph Model(Erdos-Renyi Graph)(1) Generation: : undirected graph on n nodes where each edge (u,v) appears i.i.d with probability p. : undirected graph with n nodes, and m edges picked uniformly at random. (2) Degree Distribution P(k) Binomial Distribution: . . (3) Clustering Coefficient Thus, And , so decreases with the graph size n. Note: the if . (4) Path LengthRandomly pick a node , and it will have: points whose distance is 1 points whose distance is 2 points whose distance is 3 points whose distance is At the same time, the number of vertices is . It means that: . So . In E-R Random Graph, dmax increase slowly with N. (5) Giant Component When p(n-1) &#x3D; 1, the Giant Connected Component emerges. When k&#x3D;ln N, the fully connected graph emerges. (6) Problems Degree distribution differs from that of real-world graph Giant component in most real networks does NOT emerge through a phase transition No local structure – Clustering Coefficient is too low. Conclusion: Real-world network is not random! 2. Small-world Model[Watts-Strogatz ’98] Problem: E-R random graph’s clustering is low! Need: High cluster and low diameter. Start with a low-dimensional regular lattice Has high clustering coefficient Rewire: Introduce randomness Add &#x2F; remove edges to create shortcuts to join remote parts of the lattice. For each edge, with probability p move the other endpoint to a random node. The more probability of rewiring p, the smaller clustering coefficient will be. 3. Barabasi-Albert(BA) Model Problem: How to model the power-law distribution of node degree? Solution: Introduce Growth and rich-get-richer. (1) Assumptions Growth: the graphs grows continuously Preferential attachment(i.e., rich-get-richer): nodes with larger connectivity tend to receive new edges (2) Model Definition Start with a small graph of vertices generated randomly. At each step, add a new vertex with edges connecting to distinct vertices already present in the graph. For each connection, the selection of the existing vertex is governed by the following equation.. (3)Properties The degree distribution of a BA graph follows power law distribution of γ&#x3D;3. The diameter of BA model is . 4. Kronecker Graph Model(1) Recursive Graph Generation Problem: How can we think of network structure recursively? Self-similarity Object is similar to a part of itself: the whole has the same shape as one or more of the parts. (2) Kronecker Graph Generation (3) Stochastic Kronecker Graphs Conclusion: Kronecker is similar to real-world graph.","link":"","tags":[{"name":"图计算","slug":"图计算","permalink":"https://recoderchris.github.io/tags/%E5%9B%BE%E8%AE%A1%E7%AE%97/"},{"name":"基础知识","slug":"基础知识","permalink":"https://recoderchris.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"课程笔记","slug":"课程笔记","permalink":"https://recoderchris.github.io/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"name":"PKU","slug":"PKU","permalink":"https://recoderchris.github.io/tags/PKU/"}]},{"title":"图数据管理-课程笔记1","date":"2021-02-04T12:08:11.000Z","path":"2021/02/04/图数据管理笔记1/","text":"Introduction to Graph DataI. Concept of Graph1. Origin of Graph problem [Seven Bridges of Knigsberg, 1736] The problem is to devise a walk across each of the seven bridges once and only once to touch every part of the town, or this walk does not exist. Solution: Seven Bridge Problem is to find the Euler Circuit in a graph. It is easier than finding a Hamilton Circuit. 2. Concept of Graph A graph is a set of nodes and edges that connect them. (1) Difference between Network and Graph① Network: Topology structure in a real system. Examples: Web, Social Network and Metabolic Network. Terminology: Network, Node, Link. ② Graph: Mathematical representation of network. Examples: Web Graph, Social Graphs, Knowledge Graph. Terminology: Graph, Vertex, Edge. (2) Application Field Social Network Citation Network Road Network Protein Network Knowledge Graph Internet … (3) Why Graph So Important? Graph is a general data structure to model relationships between different entities Graph provides a universal language to describe complex data Problem: Data availability and computational challenges Graph bridges Big Data and Artificial Intelligence II. Terminology in Graph1. Directed&#x2F;Undirected Graph and Vertex Degree Difference: Whether the edge has its direction. (1) Undirected Graph Properties of Edge: Symmetrical and reciprocal, i.e. (u,v)≡ (v,u) Examples: Wechat graph, Collaboration Graph Degree(v): the number of edges adjacent to vertex v. – – (2)Directed Graph Properties of Edge: Directed Examples: Weibo Following graph, Phone Call Graph Degree(v): Divide into in-degree and out-degree. And , and Source Vertex is the vertex with , and Sink Vertex is the vertex with . 2. Special Graphs(1) Clique(Complete Graph) Clique, a.k.a Complete Graph, is the undirected graph whose vertices are all connected. Number of Edges: In clique, assuming vertices, the total edge number is: . It is also the maximum of number of edge in a graph with vertices. (2) Bipartite Graph Bipartite Graph is a graph whose vertices can be divided into two disjoint sets U and V, and every edge connect between U and V. Examples: Authors-to-Papers, Buyers-to-Products 3. Representing Graphs(1) Adjacency Matrix ① Undirected Graph: Symmetric: The matrix is symmetric, that is, If Non-cyclic: for non-cyclic graph. Degree of vertex i: Total Edge of Graph: ② Directed Graph: Non-symmetric: The matrix is not symmetric, that is, . If Non-cyclic: for non-cyclic graph Degree of vertex *i*: Total Edge of Graph: ③ Disadvantages: Space Complexity: . However, the adjacency matrix is a sparse matrix. It is too much space costing. In graph processing system, adjacency matrix is totally abandoned for its expensive cost for storing. (2)Adjacency List Source Vertex Dst. 1 (Null) 2 3,4 3 2,4 4 5 5 1,2 Advantages: Easier to work when graph is large and sparse. Disadvantages: The time complexity of query a vertex is , which is time-expensive. Besides, point chasing happens when we want to find a path. (3) Compressed Sparse Representation Vertex Offset Edges 1 0 3 2 0 4 3 2 2 4 4 4 5 5 5 1 2 Offset of corresponding Vertex points to the position of vertex’s adjacency edge in Edges. Advantages: It is the most compact form of graph representation. Disadvantages: Leaving no space for dynamic graph processing. (4) Sparsity of Graph Most of graphs in real world are sparse. Conclusion: It is impossible to use adjacency matrix in graph database or processing system. In real graph computing system, we usually use compressed format to store the large-scale graph. However, it brings new challenge of building dynamic graph computing system for programmers and developers. Thus, *dynamic graph processing system* is one of the future direction for architecture researchers. Choice of the proper network representation of a given domain&#x2F;problem determines our ability to use network successfully. In some cases, there is a unique, unambiguous representation In some cases, the representation is by no means of unique The way you assign links will determine the nature of the question you study. 4. Topology Feature of Graph(1) Self-loop and Multigraph Note: In adjacency matrix, if there are 1 elements in diagonal, it is a self-loop graph. If there are , then the graph is a multigraph. (2) Connectivity① Connected Undirected Graph ② Conncted Directed Graph ③ Strong&#x2F;Weak Connected Components Weak Connected Components(WCC): Despite of direction, if the subgraph is a connected graph, then the subgraph can be called as a WCC of original Graph. 5. Some Real Graph Categories","link":"","tags":[{"name":"图计算","slug":"图计算","permalink":"https://recoderchris.github.io/tags/%E5%9B%BE%E8%AE%A1%E7%AE%97/"},{"name":"基础知识","slug":"基础知识","permalink":"https://recoderchris.github.io/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"name":"课程笔记","slug":"课程笔记","permalink":"https://recoderchris.github.io/tags/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"name":"PKU","slug":"PKU","permalink":"https://recoderchris.github.io/tags/PKU/"}]}]